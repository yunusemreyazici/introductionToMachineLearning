Nöral ağlar

Herkese merhaba. Bu videomuzda kısaca yapay sinir ağları olarak bilinen Yapay Sinir Ağları yani YSA'lardan bahsedeceğiz. Makine öğrenmesi ve derin öğrenmede en popüler modeller arasındadırlar. YSA'lar, görüntü işleme ve yüz tanıma, konuşma tanıma ve oluşturma, borsa tahminleri, hava tahmini ve daha pek çok uygulamada geniş bir yelpazede kullanılmaktadır. Özellikle doğrusal olmayan problemleri çözmek için kullanışlıdırlar ve nedenini birazdan anlayacaksınız.

Bu modeller, insan beyninin ve nöronlarının yapısından esinlenmiştir. Beyninizde 80 milyardan fazla nöron olduğunu biliyor muydunuz? Çok katmanlı kanallardan oluşan karmaşık bir ağ aracılığıyla gönderdikleri elektrokimyasal sinyalleri kullanarak birbirleriyle iletişim kurarlar. İnsan beyni birçok yönden hala bilimsel bir gizem olsa da, beyninizdeki bu biyolojik sinir ağının her yeni şey deneyimlediğinizde veya yeni bir şey öğrendiğinizde geliştiğini biliyoruz. Ve yapay sinir ağının taklit etmeye çalıştığı şey de budur.

Şimdi, bu modellerin nasıl çalıştığına daha yakından bakmanın zamanı geldi. Yapay sinir ağları, girdi verilerini alan ve gizli katmanlara gönderen bir girdi katmanına sahiptir. Birbiriyle iletişim kuran bir veya daha fazla "gizli katman" olabilir. Bilgileri “çıktı katmanına” gönderirler. Ve son olarak, çıktı katmanı çıktıyı hesaplar. Adından da anlaşılacağı gibi, gizli katmanlar süreçte gizlenir, kullanıcı onlarla değil, yalnızca giriş ve çıkış katmanlarıyla etkileşime girer. Katmanlar, “algılayıcılar” olarak adlandırılan birbirine bağlı bir dizi düğümden oluşur. Ve aslında, bu algılayıcılar insan nöronlarını taklit eder.

Bir sınıflandırma problemini çözen bir sinir ağı oluşturmaya çalışalım. Modelin bir öğrencinin bir üst sınıfa geçip geçmeyeceğini tahmin etmesini istiyoruz. Ağ, iki farklı özellikten oluşan giriş verilerini alarak başlar: sınav notları ve spor performansı. Girdi katmanı öğrencinin notları ve spor performansı ile ilgili verileri alır ve gizli katmana yönlendirir. Her nöron veya algılayıcı, ağırlıkların ve sapmanın çarpımına eklenecek bir başlangıç ​​değerine sahiptir. Bu terimleri daha önce duymuştuk: Ağırlık, her girdi için bağlantının gücünü gösterir, girdinin çıktı üzerinde ne kadar etkiye sahip olacağına karar verir. Önyargı, doğrusal regresyondaki kesişme noktasına benzer. Girdiler ve ağırlıklar çarpılır ve toplamları gizli katmandaki nöronlara gönderilir. Önyargı, her nörona uygulanır ve her nöron, toplamı elde etmek için aldığı girdileri ekler. Bu değer daha sonra aktivasyon fonksiyonundan geçer. Etkinleştirme işlevi, modelin şimdiye kadar doğrusal olan girişi dönüştürmesine izin veren doğrusal olmayan bir işlevdir. Bir eşik gibi çalışır ve çıktıyı istenilen aralık, örneğin 0,1 veya -1,1 arasında belirler, böylece algılayıcıyı etkinleştirebilir veya devre dışı bırakabilir ve değerini bir sonraki katmana geçirip geçirmeyeceğine karar verebilir. Kullanılabilecek farklı işlevler vardır, örneğin sigmoid işlevi. Bir eşik gibi çalışır ve çıktıyı istenilen aralık, örneğin 0,1 veya -1,1 arasında belirler, böylece algılayıcıyı etkinleştirebilir veya devre dışı bırakabilir ve değerini bir sonraki katmana geçirip geçirmeyeceğine karar verebilir. Kullanılabilecek farklı işlevler vardır, örneğin sigmoid işlevi. Bir eşik gibi çalışır ve çıktıyı istenilen aralık, örneğin 0,1 veya -1,1 arasında belirler, böylece algılayıcıyı etkinleştirebilir veya devre dışı bırakabilir ve değerini bir sonraki katmana geçirip geçirmeyeceğine karar verebilir. Kullanılabilecek farklı işlevler vardır, örneğin sigmoid işlevi.

Bu yaklaşımla, veriler ağ üzerinden çıkış katmanındaki nöronlara ulaşana kadar aktarılır. Her bir girdinin öğrencinin “sınıfı geçip geçmeme” olasılığını hesaplar ve çıktı olarak en yüksek olanı seçer.cVeri kümemizdeki tüm girdiler için çıktıları hesaplayabilir ve öngörülen çıktıları gerçek olanlarla karşılaştırabiliriz. Bilginin her katmandan ileriye doğru iletilmesi işlemine “ileriye yayılım” denir. İleri yayılım sürecinde, birbirine bağlı çoklu gizli katmanlar arasında pek çok gelişmiş matematiksel işlem hesaplanmaktadır.cVe eğer bu sinir ağlarının temel yapı taşı olan algılayıcılara odaklanırsak, bunların tek katmanlı sinir ağları olduğunu görebiliriz, bu yüzden onlar aynı veri işleme ilkesine sahiptir. Bunun arkasındaki matematiğe de bir göz atalım.

Örneğimizde 2 tane girdimiz var. Diyelim ki bir öğrencinin sınav notu X1, değeri 3 ve spor performansı X2, yani 8. Bu öğrencinin bir üst sınıfa geçip geçmeyeceğini öğrenmek istiyoruz. H1 ve H2 olmak üzere 2 nöronlu 1 gizli katmanımız var. Ve son olarak, bir çıkış nöronumuz var. İki katman arasındaki tüm algılayıcılar birbirine bağlandığında buna “tam bağlantılı katman” diyoruz. Her bağlantının kendisiyle ilişkili bir ağırlığı vardır. Her iki katman için sapma 1'dir. Aktivasyon fonksiyonumuz olarak, sözde adım fonksiyonunu kullanacağız. Algılayıcıların aktif olup olmayacağını belirlemek için bu durumda adım fonksiyonu mükemmel bir seçim olacaktır. Bu fonksiyonun çıktıları sadece 0 veya 1 olabilir. Bu yüzden bu gibi ikili sınıflandırma görevleri için çok kullanışlıdır. 0 eşiğine eşit veya daha büyük değerler için,

İlk olarak, X1 girişi, karşılık gelen ağırlığı W11 ile çarpılacak ve X2, karşılık gelen ağırlığı W21 ile çarpılacaktır. Ve sonuçları H1'de özetlenecektir. Değer -8'dir. Bundan sonra, 1 olan sapmayı ekleyeceğiz. Yani şimdi değer -7. Bu çıkışa aktivasyon fonksiyonunu uyguladığımızda H1 için 0 değerini elde ederiz. Benzer şekilde, 1 olan foH2 değerini hesaplıyoruz. Şimdi H1 ve H2 değerleri ile çıktıyı hesaplayabiliriz. Burada H1 ve H2'yi ağırlıklarıyla çarpıyoruz. Bu çarpımların toplamını alıp sapmayı ekliyoruz. Sonuç 1.5'tir. Aktivasyon fonksiyonunu uyguladıktan sonra 1 çıktısını alıyoruz. Böylece bu öğrenci bir sonraki sınıfa geçecektir. Modelimizi iyileştirmek için, ileriye yayılımı tamamen bitirdikten ve sonuçları temel gerçekle karşılaştırdıktan sonra, “Geri yayılım” adı verilen bir yöntem kullanabiliriz.

Artık nöral ağların nasıl çalıştığını anladığımıza göre, artık kodla oynamanın ve uygulamalı deneyim kazanmanın zamanı geldi! Bir sınıflandırma problemi ile ilgileneceğiz. Bu alıştırmada, el yazısı rakamları 28'e 28 piksel görüntülerinden sınıflandırmayı amaçlıyoruz. Bilgisayarlı görüde kullanılan standart veri setlerinden biri olan “Mnist Handwriting Digit” veri setini kullanacağız. Bilgisayar görüşü, bilgisayarları resimler, videolar vb. görsel girdilerden yararlı bilgileri algılamalarını sağlayacak şekilde eğiten bir alandır. Ve sinir ağları bunu yapmanın en iyi yöntemlerinden biridir. Mnist veri seti, sıfırdan dokuza kadar el yazısı rakamların 28'e 28 görüntüsünden 70000 örnek içerir. Her piksel için beyazdan siyaha değişen bir gri tonlama değeri vardır. Ve her görüntü için 784 piksel var.

Sklearn.datasets'i kullanarak veri kümemizi içe aktarmaya başlayalım. “OpenML”den (açık kaynak veri seti platformu) bir veri seti yüklemek için “feth_openml” kullanıyoruz. Daha sonra veri setimizi özellikler X ve hedefler y olarak böleriz. Daha sonra bunları tren ve test veri setleri olarak ayırıyoruz. Şimdi veri setimizi kontrol edelim. Bir pandas veri çerçevesi oluşturuyoruz ve ilk 5 elemanı head kullanarak yazdırıyoruz. Gördüğünüz gibi bu görseller 28'e 28 piksel olduğu için her piksel için bir tane olmak üzere 784 özelliğimiz var. Veri çerçevemizin sonuna etiket olarak hedef y'yi ekliyoruz. Ama bu sayısal veriyi bu şekilde anlamak çok kolay değil. Ayrıca imshow ve reshape fonksiyonlarını kullanarak verileri resim olarak görüntüleyebilir ve her resimdeki el yazısı rakamları görebiliriz. Sklearn.neural_network'ten bir sinir ağı sınıflandırma modeli çağıracağız. İhtiyacımız olan modelin adı MLP,

Sinir ağlarında modelin çalışma şekli bir kara kutu gibidir. Daha iyi performans gösteren bir modele yol açacak kesin ayarlamaları tahmin edemiyoruz. En iyi çözüm, farklı seçenekleri denemek ve en iyisini seçmek için bunları karşılaştırmaktır. Örneğimizde 1, 100 ve 1000 gizli katmanlı üç farklı sinir ağını eğiteceğiz. Bunu yaparak, her bir gizli katman sayısının nihai sonuçları nasıl etkilediğini görebileceğiz ve verilerimiz için hangisinin en iyi sonucu verdiğini bulabileceğiz. Etkinleştirme işlevi için, sklearn'de "lojistik" olarak anılan "lojistik sigmoid işlevi"ni seçelim. Bir sinir ağını eğitirken, bir aktivasyon fonksiyonunun seçimi ilk başta rastgeledir. Bir işlevi seçersiniz, eğer çalışırsa, başka bir işlevi seçip modelinizi tekrar eğitirseniz iyi olur. Modelimizi eğittikten sonra,

Şimdi fit fonksiyonunu kullanarak modellerimizi eğiteceğiz. Sığdırma işlevini kullandığımızda, tren veri kümesindeki tüm veri noktaları için ileri yayılım süreci gerçekleşir ve ilk ağırlıkları ve önyargıları ayarlar. Buna göre çıktılar hesaplanır. İleri yayılımdan sonra, uyum işlevi, ağırlıkları, önyargıları çapraz kontrol etmek ve ayarlamak ve hatamızı en aza indirmek için geriye gider. Bu “Geri yayılım”dır. Ağırlıklar ve yanlılık üzerindeki bu değişikliklerle, modelin eğitimi tamamlanmıştır. Artık test veri setimiz üzerinde eğitilmiş modellerimizi kullanarak tahminler yapabiliriz. Çıktı dizilerinde her görüntü için üç modelin tahminlerini görebiliriz. Gördüğünüz gibi, üç modelimiz “X_test” veri setindeki ilk görüntü için 0 tahmin etti. Ancak ikinci görsele baktığımızda ilk modelin 7 sayısını tahmin ettiğini görüyoruz, diğer ikisi ise 4 çıktısını verdi. Bu görüntüyü görselleştirelim ve hangi modelin doğru tahminde bulunduğunu kontrol edelim. imshow işlevini kullanıyoruz ve “X_test” ten ikinci görüntü için dizin olarak 1 koyuyoruz. Bu durumda daha fazla katmana sahip modellerin tahmininin doğru olduğunu gözlemleyebiliriz. Bu verilerde belirli sayıda gizli katmanın çalışıyor olması, diğer tüm projelerde en iyi şekilde çalışacağı anlamına gelmediğini unutmayın.

Son olarak, modelimizi bir karışıklık matrisi ve bir sınıflandırma raporu kullanarak değerlendirebiliriz. Karışıklık matrisinde, 10 sınıfın tümü için model tahminlerimizin ve gerçek değerlerimizin bir karşılaştırmasını görebiliriz, karışıklık matrisimizdeki köşegen çizgiden de görebileceğiniz gibi, gizli katman sayısını artırdıkça her sınıf için doğru tahminimiz artar. Sınıflandırma raporundan, genel olarak tüm sınıflar için kesinlik, hatırlama ve f1-puanı ile model doğruluğunu gözlemleyebiliriz. Sonuçlarımıza dayanarak, lojistik sigmoid fonksiyonunun iyi çalıştığını söyleyebiliriz, ancak farklı gizli katman sayılarının modelin performansını nasıl etkilediğini görelim.

Doğruluk sonuçları 1 gizli katman için %29, 100 gizli katman için %96 ve 1000 gizli katman için %97'dir. 1 gizli katman ile modelin iyi bir sınıflandırma yapamadığını ancak 100 gizli katman ile eğittiğimizde doğruluğun çok arttığını görüyoruz. Bunun nedeni, daha fazla gizli katmanla modelin verilerde daha iyi kalıplar bulabilmesidir. Ancak daha fazla katmana sahip olmak, her zaman doğruluk sonuçları arasında çok büyük bir boşluk olacağı anlamına gelmez.

Modeli 1000 gizli katmanla eğittiğimizde 100 gizli katmana göre doğruluk sonucunda sadece %1 fark elde ettik. Yapılması gereken hesaplama miktarını düşündüğümüzde %1 iyileştirme haklı değildir. Bu durumda kaynaklar ve doğruluk arasındaki dengenin 100 gizli katmana sahip bir model için daha iyi olduğunu söyleyebiliriz. Ve sinir ağları böyle çalışır!

Bu videomuzda sizlere sinir ağlarının genel yapısını algılayıcılar, girdi, gizli ve çıktı katmanları gibi bileşenleri ile tanıttık. Sonra daha derine daldık ve "ağırlıklar", "önyargı" ve "aktivasyon işlevi" terimlerini öğrendik ve son olarak modelin ileri yayılımı kullanarak bir ikili sınıflandırma görevini nasıl gerçekleştirdiğini gördük. Sinir ağlarının özellikle çok sayıda gizli katmana sahip olduklarında oldukça karmaşık yapılar haline gelebileceğini tahmin edebilirsiniz. Aslında Derin Öğrenme'deki "derin" kelimesi, gizli katmanların derinliğini ifade eder ve bu oturumla derin öğrenmeye ilk adımlarınızı attınız. Bir dahaki sefere görüşürüz!

