ekrar hoşgeldiniz! Tebrikler, kursun teorik kısmının sonuna geldiniz. Ancak henüz işiniz bitmedi, hadi öğrendiklerimizi bir araya getirelim ve uçtan uca bir makine öğrenimi projesinin nasıl oluşturulacağını keşfedelim. Bu derste atacağımız adımlar, hemen hemen her makine öğrenimi projesinde çok yaygındır ve gelecekteki projeleriniz için yol gösterici olabilirler.

Bu projede kaggle.com'dan halka açık bir veri seti olan “Mantar Sınıflandırması” veri setini kullanacağız ve bir mantarın yenilebilir olup olmadığını anlamaya çalışacağız. Bu veri seti, 23 mantar türüne karşılık gelen örneklerin açıklamalarını içerir. Her tür, yenilebilir veya zehirli olarak tanımlanır. Mantar söz konusu olduğunda, yenilebilirliği belirlemek için basit bir kural yoktur ve dikkatli olmalıyız.

Verileri etiketlediğimiz için, bu sınıflandırma sorununun üstesinden gelmek için lojistik regresyon, ridge sınıflandırıcı, karar ağacı, Naive Bayes ve sinir ağları gibi denetimli öğrenme modellerini kullanabiliriz. Bir modele yeni bir mantar hakkında bilgi verdiğimizde, örneğin yenilebilir olduğunu söyleyecektir. Bu ifadenin belirli bir oranda doğru olma şansı olacaktır. Modelleri doğruluklarına göre karşılaştıracağız ve en iyi performansı göstereni bulacağız. Önce veri setimizi yükleyelim. Veri setini platformumuzda bulabilirsiniz.

Veri setinin ön işlemesi ile başlıyoruz. Ön işlemeyi, ML algoritmalarının kullanacağı verileri hazırlamak için attığımız tüm adımlar olarak düşünebilirsiniz. Projeye bağlı olarak, dizeleri tam sayılara dönüştürmeyi, görüntüleri gri tonlamaya dönüştürmeyi, görüntüleri yeniden boyutlandırmayı veya buna benzer herhangi bir şeyi içerebilir. Bundan sonra eğitime geçeceğiz. Her zaman olduğu gibi, gerekli kitaplıkları içe aktarmakla başlayacağız. Veri seti, 8124 mantardan veri içerir. Bu mantar örneklerinin her biri 22 özelliğe sahiptir ve yenilebilir veya zehirli olarak sınıflandırılır. .csv dosyasını Pandas read_csv() yöntemini kullanarak okuyalım. data.head() fonksiyonunu kullanarak veri setine bir göz atabiliriz.

Gördüğümüz gibi, model oluşturmak için kullanabileceğimiz başlığın şekli veya rengi gibi farklı özellikler var. Ayrıca, tüm hücrelerin içinde dize tipi değerler vardır. Ancak bu daha sonra ele alacağımız bir sorundur. Şimdi, veri setini daha iyi anlamak için bazı görselleştirme tekniklerini kullanabiliriz. Örneğin bir çubuk grafik oluşturarak farklı sınıfları karşılaştırabiliriz. Sınıf başına örnek sayısını bulmakla başlayacağız. Bir Pandas DataFrame'in value_counts() yöntemi gerekli bilgileri döndürür. Artık her sınıf için çubuklar oluşturabilir ve grafiği görüntüleyebiliriz.

Yenilebilir ve zehirli örnek sayılarının birbirine çok yakın olduğunu görmekteyiz. Bu, verilerimizin dengeli olduğu anlamına gelir. Dengeli olmasaydı, modelin daha fazla örnekle sınıfa daha yatkın olma şansı daha yüksek olurdu. Ve modelimizin daha iyi genellenmesi için her sınıftaki örnek sayısını eşitlememiz gerekir.

Harika, verilerimizi daha iyi anladık. Şimdi onu özelliklere ve karşılık gelen etiketlere ayıracağız. Bizim durumumuzda sadece mantarın zehirli olup olmamasına etkisi olan sütunları kullanacağız. Bunlar “başlık şekli”, “başlık rengi”, “halka numarası” ve “halka tipi”dir. Tüm sütunları kullanmayacağımızdan, .drop()'u kullanıp "sınıfı" veri kümesinden kaldıramayız. Bunun yerine .loc() kullanacağız ve kullanacağımız özellikleri bir liste halinde vereceğiz. Daha önce de belirttiğimiz gibi değerler string formatındadır. Onlarla matematiksel işlemler yapabilmek için onları tamsayı değerlere dönüştürmemiz gerekir. Bunun için etiket kodlamasını kullanacağız. X verilerinin birden çok sütunu olduğundan, bunu bir for döngüsü içinde yapacağız, böylece tüm sütunları güncelleyebiliriz. y verileri için kodlayıcıyı doğrudan kullanabiliriz. Son verileri görmek için hem X hem de y'yi yazdıralım. Şimdi, verilerimizi eğitim ve test veri kümelerine ayırabiliriz. sklearn'den train_test_split yardımımıza geliyor.

Mükemmel! Verilerimiz kullanıma hazır! Modellerimizi eğitmeye geçelim. Makine öğreniminde, hangi modelin projemiz için en iyi performansı göstereceğini kesin olarak söyleyemeyiz. Bu yüzden her zaman farklı modelleri denemeli ve karşılaştırmalıyız. Ve elbette, her birinden en iyi sonucu almak için farklı parametreler denemeyi de düşünmeliyiz. Örneğin, bir sinir ağında daha fazla düğüm ve daha fazla katman kullanmak, daha doğru bir modele yol açabilir ancak aynı zamanda daha düşük performansa da yol açabilir. Deneme yanılma yoluyla çözmemiz gerekecek. Halihazırda ithal ettiğimiz modelleri kullanıyoruz. Daha sonra oluşturduğumuz X_train ve y_train veri seti ile tüm modelleri eğitiyoruz. X_test setini kullanarak her model için tahminler yapıyoruz ve sonuçları karşılık gelen değişkenlere kaydediyoruz. Hassasiyet, hatırlama, f-1 puanı ve doğruluğu ayrı ayrı hesaplamak yerine, performansları karşılaştırmak için sklearn'ün sınıflandırma_report işlevini kullanabiliriz. Her model için raporlar oluşturalım. Son olarak, tüm modellerin sonuçlarını yazdırıp karşılaştırıyoruz. Okunabilirliği artırmak için, basit baskı satırları kullanarak her model için başlıklar ekleyeceğiz.

%91 doğrulukla, Karar Ağacı algoritmasının tüm puan türlerinde en iyi performansı gösterdiğini görebiliriz. Doğruluklara bakıldığında, lineer regresyon, ridge regresyon ve naive bayes olmak üzere üç modelin en kötü performansı gösterdiğini görebiliriz. Karar ağacı algoritması en iyisini yaptıysa, belki işleri bir adım öteye götürebilir ve daha da iyi çalışıp çalışmadığını görmek için Rastgele Orman algoritmasını deneyebiliriz. Diğer algoritmalarla aynı adımları atacağız. Bir model oluşturun, modeli eğitin ve tahminler yapın. Şimdi iki algoritmanın sonuçlarını karşılaştırabilmemiz için sınıflandırma raporunu oluşturalım ve yazdıralım. Hem Karar Ağacı hem de Rastgele Orman algoritmalarının aynı sonucu verdiğine dikkat edin. Bu veri kümesi için Karar Ağacı veya Rastgele Orman kullanmak arasında bir fark olmadığı sonucuna varabiliriz. Modellerin başlangıç ​​değerleri rastgele üretildiği için her seferinde farklı sonuçlar elde etmek mümkündür. Modelleri değerlendirirken ve karşılaştırırken bunu daima aklınızda bulundurun. Tebrikler! Artık uçtan uca bir Makine Öğrenimi projesinin nasıl yapıldığını biliyorsunuz.

Bu projemizde makine öğrenimi uygulamaları için public bir veri setinin nasıl hazırlanacağını konuştuk. En iyi performansı göstereni bulmak için farklı modelleri birlikte eğittik ve karşılaştırdık. Burada öğrendikleriniz sizi gerçek hayattaki makine öğrenimi uygulamalarına yönlendirecektir. Bir modeli dağıtmadan önce birçok adım olsa da, bunların temel olduğunu söyleyebiliriz ve ML projelerinde farklı sorunları çözmeye hazırsınız. Öyleyse, bundan sonra neyle mücadele edeceğinize dair bir fikriniz var mı?

