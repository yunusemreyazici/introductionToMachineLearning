

AI8072 Decision trees


Url = https://globalaihub.com/courses/introduction-to-machine-learning/lessons/ai8070-models/topic/ai8072-decision-trees/


Herkese merhaba. Bu videomuzda en ünlü ve kolay anlaşılır makine öğrenimi algoritmalarından birini ele alacağız; Karar ağaçları. Karar ağaçları, sınıflandırma ve regresyon problemlerini çözmek için kullanılabilen bir tür denetimli öğrenme algoritmasıdır. Algoritma, verileri adım adım farklı kategorilere ayırmaya karar verir. Karar ağaçlarının dünyasını keşfedelim!

Size iyi haberlerimiz var ─ karar ağacı algoritmalarının arkasındaki sezgi, günlük hayatımızda karar vermek için kullandığımızla aynıdır. Örneğin, işe giderken ne giyeceğimize, tatile nereye gideceğimize, ne zaman yatacağımıza vb. karar vermemiz gerektiğinde. Diyelim ki bir sonraki tatil gezinizi planlıyorsunuz. Öncelikle nasıl bir tatil yapmak istediğinize karar vermelisiniz. Sahile gidebilir, rehberli bir tur yapabilir ve hatta bir parti tatili yapabilirsiniz. Ancak kararlar burada bitmiyor! Ayrıca yurt içi mi yoksa yurt dışı mı seyahat etmek istediğinize, kiminle gitmek istediğinize vb. karar vermelisiniz. Bu kararlar sizi nihai cevaba götürür. Gördüğünüz gibi kendinize sorduğunuz bu basit soru, verilmesi gereken birçok kararı beraberinde getiriyor ve bunların hepsi bir karar ağacı oluşturuyor.

Bu örnekte, muhtemelen tüm kararları geçmiş deneyimlerinize ve tercihlerinize, hatta arkadaşınızın önerilerine göre verebilirsiniz. Ancak, bir makine nasıl karar verebilir? Arka planda gerçekte neler oluyor? Karar ağaçları hangi soruların sorulacağını nasıl bulur? Özünde, karar ağacı algoritmaları, verilere dayalı bir sonucu tahmin etmek için kullanılabilen bir dizi if-else ifadesidir. Basitçe söylemek gerekirse, rastgele sorular sorar, veri setinin doğru bölünüp bölünmediğini kontrol eder ve soruları buna göre değiştirir.

Genel yapıya bakalım. Bir karar ağacı algoritması, doğru soru dizileri veya karşılaştırmalar içeren bir karar ağacı oluşturur. Bunlar, bir tahmin veya kategori olabilecek doğru sonuca götürecektir. Bir karar ağacı aynı zamanda bir dizi “düğüm” olarak tanımlanır. Ağacın başlangıç ​​noktasına kök veya üst düğüm denir, sonra yaprak düğüme ulaşana kadar bir dizi karar düğümümüz olur. Yaprak bizim sonucumuz, son kategorimiz veya tahminimizdir. Örneğin, genişlik ve yükseklik ölçülerine göre elma ve armutları ayırt etme problemini ele alalım. Karar ağacı böyle bir yapıya sahip olabilir. Genişlik 7.35'ten küçükse, kök düğüm karşılaştırma olur. Aksi takdirde, "Elma" yaprak düğümü son kategori olacaktır. Ancak doğruysa, bir karar düğümü şunları takip eder: Yükseklik 7.4'ten küçükse karşılaştırma. Burada, koşulun doğru olması durumunda "Elma" veya yanlış olması durumunda "Armut" şeklinde takip edebilecek iki olası yaprak düğümümüz var. Artık bir karar ağacı algoritmasının genel konseptini anladığımıza göre, onu ne zaman ve nasıl kullandığımızdan bahsedelim. Daha önce bahsedildiği gibi, karar ağaçları, bir bilgisayarın fiyatının düşük, orta veya yüksek olup olmadığını tahmin etmek gibi sınıflandırma problemlerinin yanı sıra örneğin bir evin satış fiyatını tahmin etmek gibi regresyon problemlerini çözmek için kullanılabilir.

Genel olarak, karar ağacı algoritmaları sınıflandırma problemleri için daha uygundur, ancak farklı durumlar arasında güçlü ayrımlar varsa regresyon ağaçları çok faydalıdır. Bunun nedeni, karar tabanlı algoritmaların mantığının kategorik olmasıdır, bu yüzden sınıflandırma problemlerine daha yakındır. Regresyon problemlerinde olduğu gibi sürekli değerlerin çıktısını tahmin etmek kararlara dayalı olarak daha zordur. Karar ağaçlarını kullanırken dikkate almamız gereken başka şeyler de var. Karar ağaçlarının sorular sorduğundan ve verileri bunlara göre böldüğünden daha önce bahsetmiştik. Sorulara dayanarak, bilgi kazancını hesaplayacağız. Bilgi kazanımı, bir sorunun bir sınıf hakkında ne kadar bilgi verdiğinin ölçüsüdür. Bir soru veri setini diğerinden daha iyi bölerse, o soru kullanılacaktır. Bunu elma ve armut örneğimizde görebiliriz. Örneğin, karar ağacı önce meyvenin genişliğinin 8.0'dan küçük olup olmadığını sorabilir. Verilerden de görebileceğimiz gibi, bu soru veri setini iyi bir şekilde bölmemektedir. Bizim durumumuzda daha iyi bir karşılaştırma 7.35 olacaktır, bu da daha iyi bir bilgi kazanımına yol açacaktır. Bu işlem, bilgi kazancı sıfır olana kadar tekrar eder. Çok fazla soru sormak - yani uzun bir karar ağacına sahip olmak - fazla uydurmaya yol açar. Bunun nedeni, daha fazla soruyla daha spesifik ayrıntılar aramamızdır, bu da daha az genelleştirilmiş bir model anlamına gelir. Bu işlem, bilgi kazancı sıfır olana kadar tekrar eder. Çok fazla soru sormak - yani uzun bir karar ağacına sahip olmak - fazla uydurmaya yol açar. Bunun nedeni, daha fazla soruyla daha spesifik ayrıntılar aramamızdır, bu da daha az genelleştirilmiş bir model anlamına gelir. Bu işlem, bilgi kazancı sıfır olana kadar tekrar eder. Çok fazla soru sormak - yani uzun bir karar ağacına sahip olmak - fazla uydurmaya yol açar. Bunun nedeni, daha fazla soruyla daha spesifik ayrıntılar aramamızdır, bu da daha az genelleştirilmiş bir model anlamına gelir.

Overfitting ve verilerimizde çok fazla özellik bulundurma probleminden önceki derslerde bahsetmiştik. Veri kümelerimizin çok sayıda özellik ve çok çeşitli değerler içerebileceğini biliyoruz, ancak bunların hepsi önemli değil. Karar ağaçları için “budama” adı verilen bir işlem yapabiliriz. Budama, temelde, daha az karmaşık bir karar ağacı elde etmek için bilgi kazanımına dayalı olarak bazı gereksiz özelliklerin kaldırılmasıdır. Elma ve armutları kategorize etme örneğimizde bu, meyvenin yetişme koşulları hakkında bilgi olabilir. Budama, aşırı uydurmayı ve yüksek varyansı önlemeye yardımcı olur, böylece modelimiz görünmeyen verilere iyi bir genelleme yapar. Karar ağacının performansı tıpkı diğer herhangi bir makine öğrenimi algoritması gibi ölçülür. Sınıflandırma ağaçları için karışıklık matrisi, doğruluk puanı, f1 puanı kullanırız. ve RMSE, Regresyon ağaçları için MSE. Metriklerinin sonuçlarını karar ağaçlarından elde ettiğimiz sonuçlarla karşılaştırarak diğer modellerin performansını karşılaştırabilir ve çözmeye çalıştığımız soruna uyan en uygun modeli seçebiliriz.

Peki, karar ağaçlarının ana avantajları nelerdir? Diğer algoritmalara kıyasla, karar ağaçları veri hazırlamak için daha az çaba harcar ve normalleştirmeye ve ölçeklendirmeye gerek yoktur. Verilerdeki eksik değerler, karar ağacı oluşturma sürecini önemli ölçüde etkilemez. Ama elbette bazı dezavantajları da var. Karar ağaçlarının birçok avantajı olmasına rağmen, eğitilmesi daha uzun süre gerektirir. Diğer bir sorun da karar ağaçlarının kararsız olmasıdır. Verilerdeki küçük değişiklikler, tamamen farklı bir ağacın oluşturulmasına neden olabilir. Ayrıca, karar ağaçları karmaşık veriler için fazla uygun olma eğilimindedir, bu nedenle girdiyi iyi bir şekilde genelleyemeyebilirler.

Gerçekten de, aşırı uyum çok büyük bir sorundur. Karar ağaçlarına dayalı başka bir algoritma olan rastgele ormanın devreye girdiği yer burasıdır. Rastgele orman yaklaşımı, yalnızca bir ağaç kullanmak yerine birçok ağaç kullanmasıdır. Her ağaçta bir test veri seti çalıştırır, her birinden tahminler alır ve çoğunluk oylarına göre, bu en çok görünen kategori anlamına gelir, nihai bir çıktı alırız. Ancak birçok ağaç söz konusu olduğunda, birçok veri setine ihtiyacımız var. Halihazırda bir veri setimiz olduğundan, onu kolayca daha küçük veri setlerine bölebilir ve bu setlerin her birini rastgele orman ağaçları için kullanabiliriz. Her ağaç, veri kümesinin farklı bölümlerine odaklandığından, bu, fazla uydurmayı önler.

Şimdi bu algoritmaların pratikte nasıl çalıştığına bakalım. Pratik örneğimizde, bir karar ağacı ve ardından rastgele bir orman kullanarak tahminler yapmaya çalışacağız. Ardından, sonuçları gösterecek ve karşılaştıracağız. Titanik olayı ile ilgili bir veri seti kullanacağız. “Bilet Sınıfı”, “Cinsiyet”, “Yaş”, “Titanik'teki Kardeş/Eş Sayısı”, “Titanik'teki Ebeveyn/Çocuk Sayısı”, “Yolcu Ücreti” ve “Biniş Limanı” özelliklerine göre bir kişinin hayatta kalıp kalmadığını belirlemeye çalışacak. Bu problem bir sınıflandırma problemi olduğu için karar ağaçlarını ve rastgele orman sınıflandırıcılarını kullanabiliriz. Hadi gidelim!

Şimdi örnek veri setini içe aktarıyoruz, ardından veri setimizi özellikler, X ve hedefler, y olarak ayırıyoruz. Ardından, onları tren ve test veri kümelerine ayırdık. Eğitim veri setinde bir karar ağacı ve rastgele orman sınıflandırıcısı kullanalım! Önce sklearn ve matplotlib'den plot_tree'yi içe aktarıyoruz. Adından da anlaşılacağı gibi, plot_tree, karar ağacını çizmemize izin verecektir. Test veri setine geçmeden önce karar ağacını görselleştirmek için bir kod yazabiliriz. Bu, algoritmanın karar sürecini anlamamıza yardımcı olacaktır. Önce sklearn ve matplotlib'den plot_tree'yi içe aktarıyoruz. Adından da anlaşılacağı gibi, plot_tree, karar ağacını çizmemize izin verecektir. Ayrıca fonksiyon içinde birçok argümanı ayarladığımızı da görebilirsiniz. Bunlar, daha iyi bir görselleştirme elde etmemize ve gösterilen bilgileri filtrelememize yardımcı olur. Örneğin, "maks_derinlik" bağımsız değişkeni 2 olarak ayarlanmıştır, bu, ağacın yalnızca ilk üç katmanının gösterilmesi gerektiğini belirtir. Bu bağımsız değişkenler hakkında daha fazla bilgi edinmek için plot_tree belgelerine göz atabilirsiniz. Ve son olarak arsayı gösterebiliriz.

Karar ağacının her bir düğümünde kullanılan özellikleri ve bölme değerlerini görebilirsiniz. Bu süreç, karar ağacı en iyi performans gösteren çözümde birleşene kadar devam eder. Alttaki düğümler, sadece ilk üç katmanı görmek istediğimiz için bu ağacın daha derine indiğini söylüyor. Son olarak, test veri setini kullanarak tahminler yapmaya hazırız.

Şimdi iki modeli nasıl karşılaştırabiliriz? Evet, performans metriklerini kullanabiliriz! Ve bir sınıflandırma problemiyle uğraştığımız için, kullanacağımız metrikler kesinlik puanı, hatırlama puanı, f1 puanı ve doğruluktur. Sınıflandırma raporunu göstererek, bu puanları görebileceğiz ve bu iki algoritmanın performansları arasında bir karşılaştırma yapabileceğiz. Sınıflandırma raporlarını yazdıralım ve farkı görelim. Bu sınıflandırma raporlarını gözlemleyerek, bu iki modelin performansları arasındaki farkı görebiliriz. Rastgele orman sınıflandırıcılarının tahminleri için daha yüksek kesinliklere, hatırlamalara ve f1 puanlarına sahibiz, bu nedenle daha iyi performans gösteriyor.

Bu videoda karar ağacı algoritmasını tanıttık ve arkasındaki mantığı, avantajlarını ve dezavantajlarını anladık. Karar ağacı algoritmalarımızın performansını nasıl değerlendireceğimizi de öğrendik. Rastgele orman algoritmasına baktık, nasıl çalıştığını ve bazı durumlarda neden daha iyi performans gösterdiğini öğrendik. Son olarak, pratik bir örnekle her ikisinin de nasıl kullanıldığını gördük ve sonuçlarını karşılaştırdık. Bir sonraki oturumda görüşmek üzere!

